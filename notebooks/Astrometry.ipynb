{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and refine WCS\n",
    "\n",
    "This script will try and fit a WCS to an exposure. Fiting a WCS consists of iteratively matching source and reference catalog sources where WCS is recalculated for each matching untill maximal number of iterations are achieved or untill maximal matching distance is smaller than set treshold. \n",
    "\n",
    "To perform WCS fitting we need to construct science source catalog and reference source catalog again. Because this exercise is getting a bit repetitive we will look into ways data can be persisted and loaded from disk without perfoming the Tasks again. \n",
    "\n",
    "First step is, again, to setup the Spark paths. This only needs to be run once per lifetime of a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"Something's happening.\")\n",
    "conf.setMaster(\"spark://ip-172-31-40-212.us-west-2.compute.internal:7077\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.addPyFile(\"/home/ec2-user/lsstspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Science and Reference catalogs\n",
    "\n",
    "For more details see DetectMeasureEstimate and Matching2RefCats notebooks. This is the same exact procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsstspark as ls\n",
    "\n",
    "# set up refObjLoader and refCat configurations\n",
    "refCatConf = ls.DatasetConfig()\n",
    "refCatConf.ref_dataset_name  = \"ps1_pv3_3pi_20170110\"\n",
    "refCatConf.indexer = \"HTM\"\n",
    "refCatLoc = \"s3://dinolsstspark/small_ref_cats/\"\n",
    "\n",
    "# reference object setup\n",
    "refObjConf = ls.LoadIndexedReferenceObjectsConfig()\n",
    "refObjConf.filterMap = {'u': 'g', 'Y': 'y', \"VR\": \"r\"}\n",
    "refObjConf.ref_dataset_name = refCatConf.ref_dataset_name\n",
    "\n",
    "# register exposures we want to process\n",
    "calexppath = \"s3://dinolsstspark/sci_exposures/calexp-0308355_01.fits\"\n",
    "expPathsRDD = sc.parallelize([calexppath])\n",
    "\n",
    "#ingest them as ExposureF objects\n",
    "expRDD = expPathsRDD.map(ls.toExposureF)\n",
    "\n",
    "#estimate PSF, detect and measure sources\n",
    "estDetMeas = ls.detect_and_measure(psfIterations=2, doMeasurePsf=True)\n",
    "estDetMeasRDD = expRDD.map(estDetMeas)\n",
    "\n",
    "# we only need the source catalogs - or in this case a source catalog\n",
    "scienceCatsRDD = estDetMeasRDD.map(lambda x: x[2])\n",
    "\n",
    "# create the reference catalogs\n",
    "refCatCreator = ls.create_reference_catalogs(refCatConf, refCatLoc, refObjConf)\n",
    "referenceCatsRDD = expRDD.map(refCatCreator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting WCS \n",
    "\n",
    "To fit a WCS we will be calling the `wcs_solver` wrapper function to set up and return a function `solver` that fits a new WCS. The packing order and logic are identical to that of Matching2RefCats notebook except the triplets that need to be passed into the WCS fitter require an exposure and look like: `([(scienceCat, referenceCat), exposure], [(), ], ....)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle the data together\n",
    "catPairsRDD = scienceCatsRDD.zip(referenceCatsRDD)\n",
    "catPairsWithExpRDD = catPairsRDD.zip(expRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the solver on the catalog pair with exposures now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ls.wcs_solver(max_iter=3, minMatchDistanceArcSec=0.001)\n",
    "wcsRDD = catPairsWithExpRDD.map(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the data\n",
    "\n",
    "We can inspect the returned object. I can't figure out how to plot it in matplotlib or otherwise verify it easily because they use ds9 and it's a more complex WCS than that Astropy uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lsst.afw.geom.skyWcs.skyWcs.SkyWcs at 0x7f75c05eb8b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = wcsRDD.first()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting data to disk\n",
    "\n",
    "Considering how each step is a building block for the next, persisting data to disk is a useful feature to explore in order to reduce processing times required during in interactive session. We will persist the source and reference catalogs and see how to organize processing by reading them from disk instead of creating them by mapping `detect_and_measure` and `create_reference_catalogs` to RDD of exposures.\n",
    "\n",
    "Reference catalogs are instances of `SimpleCatalog` while science catalog of sources detected on the image are instances of `SourceCatalog`. Both can be persisted to disk by calling a method `.writeFits` on them. The `persistCatalog` function from the utils module is a light wrapper around this method.\n",
    "\n",
    "The problem is apparent. Without the Butler and its policies we need a way to create file paths and file names such that no two are the same and preferably such that they remain in a form that is mapable to exposures that were used to create them. These names must be constructed in advance and then zipped with the source catalog RDD so that they match up. \n",
    "\n",
    "Unique exposure IDs can be retrieved by the `get_exposure_id` function and after zipping these IDs with source catalogs they can be persisted to disk by using the `persist_catalog` function. Both live in the utils module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposureIdsRDD = expRDD.map(ls.utils.get_exposure_id)\n",
    "sciCatsWithId  = scienceCatsRDD.zip(exposureIdsRDD)\n",
    "refCatsWithId  = referenceCatsRDD.zip(exposureIdsRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `persist_catalog` function is a wrapper to a persisting function that enables file names and file paths to be set. File names are set by providing a string consistent with python string `.format` method (i.e. `descriptiveName_{0}`) where the curly braces will be replaced by whatever id is provided bundled with the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist = ls.persist_catalog(location=\"s3://dinolsstspark/scicats\", frmt=\"sciCat_{0}.fits\")\n",
    "sciCatLocsRDD = sciCatsWithId.map(persist)\n",
    "\n",
    "persist = ls.persist_catalog(location=\"s3://dinolsstspark/refcats\", frmt=\"refCat_{0}.fits\")\n",
    "refCatLocsRDD = refCatsWithId.map(persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sci Cat locations:  ['~/s3-drive/scicats/sciCat_30835501.fits']\n",
      "Ref Cat locations:  ['~/s3-drive/refcats/refCat_30835501.fits']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sci Cat locations: \", sciCatLocsRDD.collect())\n",
    "print(\"Ref Cat locations: \", refCatLocsRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from disk\n",
    "\n",
    "What remains is to see how to load that persisted dataset from disk and avoid creating them in the future. Unfortunately I could not come up with anything meaningful here except mapping the exact LSST datatypes `.readFits` methods to them. This is why Butler is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "referenceCatsRDD = refCatLocsRDD.map(ls.utils.get_simple_catalog)\n",
    "scienceCatsRDD   = sciCatLocsRDD.map(ls.utils.get_source_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'lsst.afw.table.simple.simple.SimpleCatalog'>\n",
       "        id           coord_ra      coord_dec    ...   centroid_y   hasCentroid\n",
       "                       rad            rad       ...                           \n",
       "----------------- ------------- --------------- ... -------------- -----------\n",
       "77931960590339852 3.42187543438 -0.437211352197 ...  1980.72917493        True\n",
       "77931961667799703 3.42375616101 -0.437213817775 ...  3316.85976403        True\n",
       "77931961833919988 3.42404509708 -0.437209744983 ...  3522.05435308        True\n",
       "77931962033659504 3.42439471897  -0.43721671333 ...  3770.40555706        True\n",
       "77941958772067733 3.41870249524 -0.437100500595 ... -274.511046018        True\n",
       "77941958851788561 3.41884168367  -0.43708772983 ... -175.727643903        True\n",
       "77941958880372033 3.41889069887 -0.437180284547 ...   -140.1856968        True\n",
       "77941958891654634 3.41891037123 -0.437142515085 ... -126.509342847        True\n",
       "77941958906214945 3.41893576869 -0.437137568583 ... -108.505243617        True\n",
       "77941958969912696 3.41904701837 -0.437170608664 ... -29.2133698368        True\n",
       "              ...           ...             ... ...            ...         ...\n",
       "78171958936481016 3.41898934803 -0.433849494969 ...  -87.287718517        True\n",
       "78171958977210724 3.41905961973 -0.433854393658 ... -37.2341575084        True\n",
       "78171959094970169 3.41926702917 -0.433864354726 ...  110.482432705        True\n",
       "78171959379021463 3.41976139596 -0.433843214522 ...   462.44285577        True\n",
       "78171959688040461 3.42030021136 -0.433858402329 ...  846.011083417        True\n",
       "78171959744081428 3.42039836539 -0.433844704117 ...   915.85610744        True\n",
       "78171959863950629 3.42060792454 -0.433855189206 ...  1065.01457435        True\n",
       "78171960156251148 3.42112053048 -0.433851136571 ...  1429.80124829        True\n",
       "78171960279630205 3.42133339468 -0.433861143469 ...    1581.282025        True\n",
       "78171962481560243  3.4251754078 -0.433860674456 ...  4315.48666147        True\n",
       "Length = 3042 rows"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referenceCatsRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'lsst.afw.table.source.source.SourceCatalog'>\n",
       " id     coord_ra      coord_dec    ... calib_psfUsed calib_psf_reserved\n",
       "          rad            rad       ...                                 \n",
       "---- ------------- --------------- ... ------------- ------------------\n",
       "   1 3.41911845014 -0.434563239167 ...         False              False\n",
       "   2 3.41911594273 -0.435494980064 ...         False              False\n",
       "   3 3.41913114669 -0.435591787724 ...         False              False\n",
       "   4 3.41911046645 -0.435664214954 ...         False              False\n",
       "   5 3.41911697767 -0.435167869754 ...         False              False\n",
       "   6 3.41912025616  -0.43600637788 ...         False              False\n",
       "   7 3.41912053567 -0.436575041883 ...         False              False\n",
       "   8 3.41913114008 -0.435530673985 ...         False              False\n",
       "   9 3.41912734772  -0.43604344957 ...         False              False\n",
       "  10 3.41913992651 -0.435909475664 ...         False              False\n",
       " ...           ...             ... ...           ...                ...\n",
       "1161 3.42481679791  -0.43494531013 ...         False              False\n",
       "1162  3.4248218839 -0.434620151737 ...         False              False\n",
       "1163 3.42481905375  -0.43570164051 ...         False              False\n",
       "1164 3.42482710457 -0.434716821703 ...         False              False\n",
       "1165 3.42483061077 -0.436558778005 ...         False              False\n",
       "1166 3.42484254023 -0.436753266854 ...         False              False\n",
       "1167 3.42484239587 -0.434761340829 ...         False              False\n",
       "1168  3.4248524939 -0.434260797531 ...         False              False\n",
       "1169 3.42484373451 -0.436212921867 ...         False              False\n",
       "1170 3.42484490888  -0.43626884854 ...         False              False\n",
       "Length = 1170 rows"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scienceCatsRDD.first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsst",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
